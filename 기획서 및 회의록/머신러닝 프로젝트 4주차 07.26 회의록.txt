분석 배경

1.
요즘 네이버, 토스, 카카오 등 금융사업에 뛰어드는 플랫폼이 많아지고 있다

그 흐름에 따라 각 은행들과 카드사들도 덩달아 신규고객을 뺏기지 않기 위해  신규고객을 유치하려 노력하고 있다.

이러한 마케팅으로 카드사를 옮기는 고객들이 많아지면서 은행과 카드사의 휴면고객 또한 증가하고 있다.

하지만 우리은행의 경우 신규고객보다 기존회원 중 휴면 회원에 집중하여 영업이익을 낸 사례가 있다.

우리는 이 사례를 바탕으로 기존고객과 휴면고객의 이탈을 막을 수 있도록 이탈 예측 모델을 구축해보려 한다 


2.
신규 은행들이 나타남에 따라 기존 카드사들도 공격적인 신규 고객 유입을 위한 마켓팅을 실시, 이에 따른 휴면 계좌 및 카드의 증가로 많은 카드사들이 손해를 보고 우리 은행은 이를 회복하기 위해 리텐션 마켓팅을 실시하여 큰 수익

"1000만장을 깨워라"… 카드사 리텐션 경쟁
https://biz.newdaily.co.kr/site/data/html/2022/06/13/2022061300061.html

https://yozm.wishket.com/magazine/detail/1517/

https://blog.hanabank.com/1660

https://www.elancer.co.kr/blog/view?seq=117

https://www.fntimes.com/html/view.php?ud=2020020718003211468a55064dd1_18

https://yozm.wishket.com/magazine/detail/1517/

https://www.dailyimpact.co.kr/news/articleView.htm

https://news.mt.co.kr/mtview.php?no=2023030623033613660

https://www.card-gorilla.com/contents/detail/1758

https://gongsi.crefia.or.kr/portal/creditcard/creditcardDisclosureDetail10?cgcMode=10

https://www.hankyung.com/economy/article/2022101861316

-------------------------------------------------------------------------------------------------------------

데이터 분석 및 전처리

1. 데이터 탐색
1) eda 
-
-
-
2) 1차 변수 선정

- 고객번호, 나이브베이 컬럼2개 총 3개 드롭


2. 데이터 전처리
1)기초전처리
- 결측치 없음, 컬럼명 및 순서 변경
- 이상치 없음
2) 모델링 준비
- 변수 인코딩
- 데이터 스케일링(standard)
- train/test분리

3. 모델 학습
1) feature selection
RFECV(Recursive Feature Elimination with Cross Validation)로 모델(로지스틱 회귀, 랜덤포레스트, xgboost)의 최적의 피쳐 개수를 찾음(8~9개)

8개와 9개 모델 평가 지표 분석을 통해  9개가 최적이라고 생각함

상관계수, 박스 플롯을 기반으로 9개 변수 선정

2) 파라미터 튜닝
그리드서치cv, (xgboost는 베이지안 추가) 
오버샘플링 기법 4개 비교(간단 설명 필요)

4. 성과평가
1)사용 알고리즘 :4개(장단점 설명)
로지스틱 회귀
랜덤 포레스트
KNN
XGBoost

- 모델 선정 설명

로지스틱 회귀:

이진 분류 문제에 적합한 선형 모델입니다.
계수들의 해석이 용이하고, 모델이 간단하여 학습과 예측이 빠릅니다.
변수들 간의 선형 관계를 고려합니다.
다중공선성이 존재할 경우, 성능이 저하될 수 있습니다.
비교적 작은 데이터셋에서도 잘 동작합니다.

랜덤 포레스트:

높은 예측 성능을 보이는 앙상블 모델 중 하나입니다.
결정 트리들의 조합으로 구성되어, 과대적합을 줄이고 안정적인 예측 성능을 제공합니다.
변수들의 중요도를 평가할 수 있어, 변수 선택에 도움이 됩니다.
트리 기반 모델이므로 선형적인 관계를 고려하지 않습니다.
학습 속도가 상대적으로 느릴 수 있습니다.

k-최근접 이웃(KNN):

간단하고 직관적인 알고리즘입니다.
인스턴스 기반 모델로 데이터에 의존적입니다.
데이터의 분포에 민감하여, 이상치에 영향을 받을 수 있습니다.
변수들 간의 선형 또는 비선형 관계를 고려하지 않습니다.
데이터가 매우 크면 예측 속도가 느려질 수 있습니다.

XGBoost:

부스팅 알고리즘으로, 랜덤 포레스트보다 높은 예측 성능을 보이는 경우가 많습니다.
과적합에 강하고, 높은 일반화 성능을 제공합니다.
변수들의 중요도를 평가할 수 있습니다.
트리 기반 모델이므로 선형적인 관계를 고려하지 않습니다.
학습 시간이 랜덤 포레스트보다 오래 걸릴 수 있습니다.


2)성과비교
accuracy
precision
recall
f1-score
auc_roc
specificity
neg pred value
confusion matrix

5. 모델학습
1) 변수 중요도(9개 피쳐)
xgboost 변수 중요도, 랜덤포레스트 피쳐임포턴스, 퍼뮤테이션 임포턴스, shap 밸류
> 중요변수 및 영향력파악

2) 시사점 및 한계점
- 분석 의의

- 분석 한계점

데이터 비식별화 처리 > 추가 외부변수 수집 한계

실제 상황과는 맞지 않는 가상 데이터 >데이터 이해와 모델 적용에 한계가 생김



내일 6~7시 사이 ppt 확인 회의!



